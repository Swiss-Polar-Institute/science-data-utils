{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antarctic Circumnavigation Expedition Cruise Track data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLONASS and Trimble GPS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps as described here: http://epic.awi.de/48174/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import MySQLdb\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 - Extract data from database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from a database table into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_database(query, db_connection):\n",
    "    \n",
    "    dataframe = pd.read_sql(query, con=db_connection)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPS data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_trimble = 'select * from ship_data_gpggagpsfix where device_id=63;'\n",
    "password = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_connection = MySQLdb.connect(host = 'localhost', user = 'ace', passwd = password, db = 'ace2016', port = 3306); \n",
    "\n",
    "gpsdb_df = get_data_from_database(query_trimble, db_connection)\n",
    "#gpsdb_df_opt = optimise_dataframe(gpsdb_df_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpsdb_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of data points output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(gpsdb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates and times covered by the Trimble data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Start date:\", gpsdb_df['date_time'].min())\n",
    "print(\"End date:\", gpsdb_df['date_time'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the data into monthly files (to be able to plot them to visually screen the obvious outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpsdb_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpsdb_df['date_time_day'] = gpsdb_df['date_time'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpsdb_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days = gpsdb_df.groupby('date_time_day')\n",
    "for day in days.groups:\n",
    "    path = '/home/jen/ace_trimble_gps_' + str(day) + '.csv'\n",
    "    days.get_group(day).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GLONASS data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_glonass = 'select * from ship_data_gpggagpsfix where device_id=64;'\n",
    "\n",
    "password = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_connection = MySQLdb.connect(host = 'localhost', user = 'ace', passwd = password, db = 'ace2016', port = 3306); \n",
    "\n",
    "glonassdb_df = get_data_from_database(query_glonass, db_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glonassdb_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of data points output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(glonassdb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates and times covered by the GLONASS data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Start date:\", glonassdb_df['date_time'].min())\n",
    "print(\"End date:\", glonassdb_df['date_time'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the data into monthly files (to be able to plot them to visually screen the obvious outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glonassdb_df['date_time_day'] = glonassdb_df['date_time'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glonassdb_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = glonassdb_df.groupby('date_time_day')\n",
    "for day in days.groups:\n",
    "    path = '/home/jen/ace_glonass_' + str(day) + '.csv'\n",
    "    days.get_group(day).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 - Visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimble GPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in the form of the daily csv files, were imported into QGIS mapping software in order to manually visually inspect the data points. This was done at a resolution of 1:100,000.\n",
    "\n",
    "There were no obvious outlying points. \n",
    "Number of points flagged as outliers: 0\n",
    "\n",
    "The following sections were identified as unusual and have been classified in the table below: \n",
    "| Start date and time (UTC) | End date and time (UTC) | Potential problem |\n",
    "|---------|-----------|----------|\n",
    "| 2016-12-21 10:15:46.620 | 2016-12-21 10:16:35.620 | Overlapping track |\n",
    "| 2016-12-21 07:37:16.470 | 2016-12-21 07:40:02.470 | Overlapping track |\n",
    "| 2016-12-22 04:43:10.010 | 2016-12-22 04:43:14.010 | Overlapping track |\n",
    "| 2016-12-22 09:38:40.270 | 2016-12-22 09:38:41.270 | Strange gap |\n",
    "| 2016-12-23 00:15:22.060 | 2016-12-23 00:15:33.060 | Overlapping track |\n",
    "| 2016-12-23 04:57:57.310 | 2016-12-23 04:57:58.310 | Large gap |\n",
    "| 2016-12-23 05:05:05.310 | 2016-12-23 05:11:43.540 | Overlapping track |\n",
    "| 2016-12-23 05:30:01.560 | 2016-12-23 05:30:04.560 | Large gap |\n",
    "| 2016-12-25 06:04:50.900 | 2016-12-25 06:09:52.980 | Overlapping track |\n",
    "| 2016-12-29 12:57:59.390 | 2016-12-29 14:57:34.730 | Strange diversion |\n",
    "| 2016-12-30 04:53:24.840 | 2016-12-30 08:51:12.670 | Strange diversion, missing data |\n",
    "| 2016-12-31 00:51:37.580 | 2016-12-31 00:51:39.580 | |\n",
    "| 2017-01-01 11:54:29.820 | 2017-01-01 11:54:41.820 | Overlapping track |\n",
    "| 2017-01-01 22:51:51.680 | 2017-01-01 22:54:41.700 | Strange deflection |\n",
    "| 2017-01-01 22:56:05.700 | 2017-01-01 22:59:57.700 | Strange deflection |\n",
    "| 2017-01-04 00:34:30.360 | 2017-01-04 00:34:33.360 | Large move |\n",
    "| 2017-01-13 08:26:40.850 | 2017-01-13 08:30:36.840 | Strange deflection |\n",
    "| 2017-03-11 06:47:22.300 | 2017-03-11 08:21:40.970 | Strange deflection |\n",
    "| 2017-03-16 17:51:36.490 | 2017-03-16 18:12:21.470 | Gap with jump |\n",
    "| 2017-03-17 15:29:07.620 | 2017-03-17 15:29:10.620 | Gap with jump |\n",
    "| 2017-03-18 04:07:31.290 | 2017-03-18 04:07:32.290 | Gap with jump |\n",
    "| 2017-03-18 12:43:22.100 | 2017-03-18 12:43:42.100 | Overlapping track |\n",
    "| 2017-03-18 13:01:04.100 | 2017-03-18 19:09:28.440 | Large gap with large time difference |\n",
    "| 2017-03-24 10:13:24.720 | 2017-03-24 10:13:25.720 | Gap with jump |\n",
    "| 2017-03-25 10:07:08.990 | 2017-03-25 10:07:15.990 | Gap with jump |\n",
    "| 2017-03-26 22:25:49.940 | 2017-03-26 22:25:50.940 | Gap with jump |\n",
    "These points have not been flagged but will be returned to later on in the processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLONASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in the form of the daily csv files, were imported into QGIS mapping software in order to manually visually inspect the data points. This was done at a resolution of 1:100,000.\n",
    "\n",
    "There were no obvious outlying points. \n",
    "Number of points flagged as outliers: 0\n",
    "    \n",
    "The following sections were identified as unusual and have been classified in the table below: \n",
    "| Start date and time (UTC) | End date and time (UTC) | Potential problem |\n",
    "|---------|-----------|----------|\n",
    "| 2017-04-06 15:26:30 | 2017-04-06 15:26:32 | Gap with jump |\n",
    "| 2017-04-06 18:22:07 | 2017-04-06 18:22:09 | Gap with jump |\n",
    "| 2017-04-06 21:41:21 | 2017-04-06 21:41:45 | Strange deflection |\n",
    "| 2017-04-07 15:25:06 | 2017-04-07 15:25:13 | Strange deflection |\n",
    "| 2017-04-08 04:12:44 | 2017-04-08 04:13:27 | Strange deflection |\n",
    "| 2017-04-08 05:01:34 | 2017-04-08 05:01:49 | Strange deflection |\n",
    "| 2017-04-08 18:42:12 | 2017-04-08 18:43:04 | Strange deflection |\n",
    "| 2017-04-08 18:56:02 | 2017-04-08 18:57:27 | Strange deflection |\n",
    "| 2017-04-08 19:00:26 | 2017-04-08 19:01:03 | Strange deflection |\n",
    "| 2017-04-08 19:05:31 | 2017-04-08 19:05:46 | Strange deflection |\n",
    "| 2017-04-10 02:43:40 | 2017-04-10 02:44:25 | Strange deflection |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 - Motion data correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 - Automated data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data point will be compared with the one before and after to automatically filter out points that are out of the conceivable range of the ship's movement.'\n",
    "\n",
    "The second of two consecutive points to be flagged as \"likely incorrect\" when any of the following cases occur: \n",
    "    - speed between two points >= 20 knots\n",
    "    - acceleration between two points >= 1 ms^-2\n",
    "    - direction between two points >= 5 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "df_test = gpsdb_df.head(10000)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "datetime = \"2017-03-17 11:34:26.410\"\n",
    "gpsdb_df[gpsdb_df.date_time == datetime].latitude.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_location(datetime, position_df):\n",
    "    \"\"\"Create a tuple of the date_time, latitude and longitude of a location in a dataframe from a given date_time.\"\"\"\n",
    "    \n",
    "    latitude = position_df[position_df.date_time == datetime].latitude.item()\n",
    "    longitude = position_df[position_df.date_time == datetime].longitude.item()\n",
    "    \n",
    "    location = (datetime, latitude, longitude)\n",
    "    \n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "datetime = \"2017-03-17 11:34:27.410\"\n",
    "position_df = gpsdb_df\n",
    "location = get_location(datetime, position_df)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_distance(origin, destination):\n",
    "    \"\"\"Calculate the haversine or great-circle distance in metres between two points with latitudes and longitudes, where they are known as the origin and destination.\"\"\"\n",
    "    \n",
    "    datetime1, lat1, lon1 = origin\n",
    "    datetime2, lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "    \n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) \\\n",
    "                                                  * math.cos(math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c # Distance in km\n",
    "    d_m = d*1000 # Distance in metres\n",
    "    \n",
    "    return d_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "origin_datetime = \"2017-03-17 11:34:26.410\"\n",
    "destination_datetime = \"2017-03-17 11:34:27.410\"\n",
    "position_df = gpsdb_df\n",
    "\n",
    "origin = get_location(origin_datetime, position_df)\n",
    "destination = get_location(destination_datetime, position_df)\n",
    "\n",
    "print(\"Origin:\", origin)\n",
    "print(\"Destination:\", destination)\n",
    "\n",
    "distance = calculate_distance(origin, destination)\n",
    "print(\"Distance:\", distance, \"m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knots_two_points(location1, location2):\n",
    "    \"\"\"Calculate the speed in knots between two locations which are dictionaries containing latitude, longitude and date_time.\"\"\"\n",
    "    \n",
    "    distance = calculate_distance(location1, location2)\n",
    "    \n",
    "    datetime_str1, lat1, lon1 = origin\n",
    "    datetime_str2, lat2, lon2 = destination\n",
    "    \n",
    "    datetime1 = datetime.datetime.strptime(datetime_str1,\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    datetime2 = datetime.datetime.strptime(datetime_str2,\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    seconds = abs((datetime1) - (datetime2)).total_seconds()\n",
    "    \n",
    "    conversion = 3600/1852 # convert 1 ms-1 to knots (nautical miles per hour; 1 nm = 1852 metres)\n",
    "    speed_knots = (distance/seconds) * conversion\n",
    "    \n",
    "    if seconds > 0:\n",
    "        return speed_knots\n",
    "    else:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "speed = knots_two_points(origin, destination)\n",
    "print(\"Speed: \", speed, \"knots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_utc(date_time):\n",
    "    \"\"\"Set the timezone to be UTC.\"\"\"\n",
    "    utc = datetime.timezone(datetime.timedelta(0))\n",
    "    date_time = date_time.replace(tzinfo=utc)\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = gpsdb_df[['date_time', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "df_test = gpsdb_df.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyse_speed(position_df):\n",
    "    \"\"\"Analyse the cruise track to ensure each point lies within a reasonable distance and direction from the previous point.\"\"\"\n",
    "    \n",
    "    total_data_points = len(position_df)\n",
    "    \n",
    "    earliest_date_time = position_df['date_time'].min()\n",
    "    latest_date_time = position_df['date_time'].max()\n",
    "\n",
    "    current_date = earliest_date_time\n",
    "\n",
    "    previous_position = get_location(earliest_date_time, position_df)\n",
    "    datetime_previous, latitude_previous, longitude_previous = previous_position\n",
    "      \n",
    "    count_speed_errors = 0\n",
    "        \n",
    "    for position in position_df.itertuples():\n",
    " \n",
    "        current_position = position[2:5]\n",
    "        row_id = position[1]\n",
    "        \n",
    "        speed_knots = knots_two_points(previous_position, current_position)\n",
    "\n",
    "        error_message = \"\"\n",
    "\n",
    "        if speed_knots == \"N/A\":\n",
    "            error_message = \"No speed?\"\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_speed'] = 9\n",
    "            print(position_df['id' == row_id])\n",
    "        elif speed_knots >= 20:\n",
    "            error_message += \"** Too fast **\"\n",
    "            #print(row_id)\n",
    "            #print(position_df[position_df['id'] == row_id])\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_speed'] = 4\n",
    "            count_speed_errors += 1\n",
    "        elif speed_knots < 20:\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_speed'] = 1\n",
    "\n",
    "        if error_message != \"\":\n",
    "            print(\"Error {} {}   ({:.4f}, {:.4f})   speed: {} knots\".format(error_message, current_position[0], current_position[1], current_position[2], speed_knots))\n",
    "\n",
    "        previous_position = current_position\n",
    "        \n",
    "    return count_speed_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "analyse_speed(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_bearing(origin, destination):\n",
    "    \"\"\"Calculate the direction turned between two points.\"\"\"\n",
    "    \n",
    "    datetime1, lat1, lon1 = origin\n",
    "    datetime2, lat2, lon2 = destination\n",
    "    \n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    \n",
    "    bearing = math.atan2(math.sin(dlon) * math.cos(math.radians(lat2)), \n",
    "                         math.cos(math.radians(lat1)) * math.sin(math.radians(lat2)) \n",
    "                         - math.sin(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.cos(dlon))\n",
    "    \n",
    "    bearing_degrees = math.degrees(bearing)\n",
    "    \n",
    "    return bearing_degrees\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_bearing_difference(current_bearing, previous_bearing):\n",
    "    \"\"\"Calculate the difference between two bearings, based on bearings between 0 and 360.\"\"\"\n",
    "    \n",
    "    difference = current_bearing - previous_bearing\n",
    "\n",
    "    while difference < -180:\n",
    "        difference += 360\n",
    "    while difference > 180:\n",
    "        difference -= 360\n",
    "    \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "bearing = calculate_bearing(origin, destination)\n",
    "print(math.degrees(bearing), \"degrees\")\n",
    "\n",
    "current_bearing = 355\n",
    "previous_bearing = 5\n",
    "\n",
    "difference = calculate_bearing_difference(current_bearing, previous_bearing)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_course(position_df):\n",
    "    \"\"\"Analyse the change in the course between two points regarding the bearing and acceleration - these features need information from previous points.\"\"\"\n",
    "    \n",
    "    total_data_points = len(position_df)\n",
    "    \n",
    "    earliest_date_time = position_df['date_time'].min()\n",
    "    current_date = earliest_date_time\n",
    "    \n",
    "    previous_position = get_location(earliest_date_time, position_df)\n",
    "    datetime_previous, latitude_previous, longitude_previous = previous_position\n",
    "     \n",
    "    previous_bearing = 0\n",
    "    previous_speed_knots = 0\n",
    "\n",
    "    count_bearing_errors = 0\n",
    "    count_acceleration_errors = 0      \n",
    "\n",
    "    for position in position_df.itertuples():\n",
    "\n",
    "        current_position = position[2:5]\n",
    "        row_id = position[1]\n",
    "\n",
    "        # Calculate bearing and change in bearing\n",
    "        current_bearing = calculate_bearing(previous_position, current_position)\n",
    "        difference_in_bearing = calculate_bearing_difference(current_bearing, previous_bearing)\n",
    "        \n",
    "        # Calculate acceleration between two points\n",
    "        current_speed_knots = knots_two_points(previous_position, current_position)\n",
    "\n",
    "        time_difference = (current_position[0] - previous_position[0]).total_seconds()\n",
    "        speed_difference_metres_per_sec = (current_speed_knots - previous_speed_knots) * (1852/3600) # convert knots to ms-1 \n",
    "        \n",
    "        if time_difference >0:\n",
    "            acceleration = speed_difference_metres_per_sec / time_difference\n",
    "        else:\n",
    "            acceleration = 0\n",
    "\n",
    "        # Print errors where data do not meet requirements\n",
    "        error_message_bearing = \"\"\n",
    "        error_message_acceleration = \"\"\n",
    "\n",
    "        if difference_in_bearing == \"N/A\":\n",
    "            error_message_bearing = \"No bearing?\"\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_course'] = 9\n",
    "            print(row_id)\n",
    "            #print(position_df['id' == row_id])\n",
    "        elif difference_in_bearing >= 5:\n",
    "            error_message_bearing = \"** Turn too tight **\"\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_speed'] = 4\n",
    "            print(row_id)\n",
    "            #print(position_df['id' == row_id])\n",
    "            count_bearing_errors += 1\n",
    "\n",
    "        if error_message_bearing != \"\":\n",
    "            print(\"Error:  {} {} ({:.4f}, {:.4f}) bearing change: {} degrees\".format(error_message_bearing, current_position[0], current_position[1], current_position[2], difference_in_bearing))\n",
    "            \n",
    "        if acceleration ==\"N/A\":\n",
    "            error_message_acceleration = \"No acceleration\"\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_course'] = 9\n",
    "            print(row_id)\n",
    "            #print(position_df['id' == row_id])\n",
    "        elif acceleration > 1:\n",
    "            count_acceleration_errors += 1\n",
    "            error_message_acceleration = \"** Acceleration to quick **\"\n",
    "            position_df.loc[position_df['id'] == row_id, 'measureland_qualifier_flag_course'] = 4\n",
    "            print(row_id)\n",
    "            #print(position_df['id' == row_id])\n",
    "            \n",
    "        if error_message_acceleration != \"\":\n",
    "            print(\"Error:  {} {} ({:.4f}, {:.4f}) acceleration: {} ms-2\".format(error_message_acceleration, current_position[0], current_position[1], current_position[2], acceleration))\n",
    "\n",
    "        previous_position = current_position\n",
    "        previous_bearing = current_bearing\n",
    "        previous_speed_knots = current_speed_knots\n",
    "        \n",
    "    return (count_bearing_errors, count_acceleration_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "analyse_course(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
